{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Genetic Algorithm to determine query weights for retrieval of relevant document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are trying to learn weighting the terms in a query so as to return the more relevant document from a document set. Here, we have considered two very simple documents and a query called \"gold silver truck\". In order to also compare whether our evolutionary algorithm learns weights well, we compare its performance to cosine similarity computed via the traditional multiplication of tf-idf matrices of query with both the documents. The goal is to learn weights in order to get higher similarity for the relevant document compared to a document not so relevant. Firstly, we prepare the documents by tokenizing the sentences and getting a bag of words from the contents of both the documents. Next, functions to compute tf-idf has been written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach:\n",
    "1. define the 2 documents\n",
    "2. Get the words by tokenization\n",
    "3. Generate bow from the 2 documents\n",
    "4. Generate tf and idf scores for both the documents\n",
    "5. In order to learn the weights for the terms in the query; we first define certain rules. For starting off, we are considering 100 iterations to learn the weights. At each iteration, we are considering a population of 10 relevant weights for the query terms. \n",
    "6. Firstly, we generate a random weights matrix of 10 rows of weights for all terms in bow\n",
    "7. In each iteration, we first find the cosine similarity of the each row of the weights with the 2 documents and rank them in descending order of similarity\n",
    "8. The top 4 similar weight rows are selected - these are our parent chromosomes for that iteration. From these parent chromosomes, using one point crossover; we get 6 more chromosomes and these 10 chromosomes are now used to recalculate the similarity with the document. The cosine similarity serves as our fitness function here\n",
    "9. Halfway through the iterations, i.e. the 51st iteration, we incorporate mutation to change the bits in our best weights( the best set of the weights is the first row in our matrix of weights) by multiplying certain elements in the first row by 1.1\n",
    "10. On the completion of specified number of iterations, we return the query weights learned and using the query weights; we return the similarity compuatation between both the documents and our query\n",
    "11. To test the performace of our Genetic algorithm; we have used sklearn tfidf vectorizer and computed similarity of the documents with the qery using tf-idf of both query and documents. We see a better performance by GA in just 100 iterations. The GA algorithm gives us 78% similarity with first document and 53% similarity with second comapred to normal similarity computation whcih ranks document 1 being most relevant at a 70% similarity. We get an increase of 8% in similarity compuation using GA which is useful if we have many documents in our corpus and have to find most reklevant documents. Since, the more distance between the similarity measure across documents, the easier it is to rank or threshold them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the 2 documents considered\n",
    "documentA = \"delivery of silver arrived in a silver truck\"\n",
    "documentB = \"shipment of gold arrived in a truck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the documents to extract the words in each document\n",
    "bowA = documentA.split(\" \")\n",
    "bowB = documentB.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all the unique words in the bag of words for both the documents\n",
    "wordSet = set(bowA).union(set(bowB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionaries to keep the word counts\n",
    "wordDictA = dict.fromkeys(wordSet,0)\n",
    "wordDictB = dict.fromkeys(wordSet,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the words in bags\n",
    "for word in bowA:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "for word in bowB:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>arrived</th>\n",
       "      <th>delivery</th>\n",
       "      <th>gold</th>\n",
       "      <th>in</th>\n",
       "      <th>of</th>\n",
       "      <th>shipment</th>\n",
       "      <th>silver</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  arrived  delivery  gold  in  of  shipment  silver  truck\n",
       "0  1        1         1     0   1   1         0       2      1\n",
       "1  1        1         0     1   1   1         1       0      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Into matrix\n",
    "import pandas as pd\n",
    "pd.DataFrame([wordDictA,wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF\n",
    "def computeTF(wordDict,bow):\n",
    "    tfDict={}\n",
    "    bowCount=len(bow)\n",
    "    for word,count in wordDict.items():\n",
    "        tfDict[word]=count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfBowA = computeTF(wordDictA,bowA)\n",
    "tfBowB = computeTF(wordDictB,bowB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDF \n",
    "def computeIDF(docList):\n",
    "    import math\n",
    "    idfDict={}\n",
    "    N=len(docList)\n",
    "    #count the no. of docs that contain a word w\n",
    "    idfDict = dict.fromkeys(docList[0].keys(),0)\n",
    "    for doc in docList:\n",
    "        for word,val in doc.items():\n",
    "            if(val>0):\n",
    "                idfDict[word]+=1\n",
    "                \n",
    "    #divide N by denominator above, take the log of that\n",
    "    for word,val in idfDict.items():\n",
    "        idfDict[word]=math.log(N/float(val))\n",
    "    \n",
    "    return idfDict\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs=computeIDF([wordDictA,wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow,idfs):\n",
    "    tfidf={}\n",
    "    for word,val in tfBow.items():\n",
    "        tfidf[word]=val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA=computeTFIDF(tfBowA,idfs)\n",
    "tfidfBowB=computeTFIDF(tfBowB,idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>arrived</th>\n",
       "      <th>delivery</th>\n",
       "      <th>gold</th>\n",
       "      <th>in</th>\n",
       "      <th>of</th>\n",
       "      <th>shipment</th>\n",
       "      <th>silver</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  arrived  delivery      gold   in   of  shipment    silver  truck\n",
       "0  0.0      0.0  0.086643  0.000000  0.0  0.0  0.000000  0.173287    0.0\n",
       "1  0.0      0.0  0.000000  0.099021  0.0  0.0  0.099021  0.000000    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfBowA,tfidfBowB])\n",
    "#Code until here was taken from  -----> https://www.youtube.com/watch?v=hXNbFNCgPfY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, the tf-idf scores for the 2 documents are stored in two arrays called dataSet1 and dataSetII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "dataSetI = [0.0,0.0,0.086643,0.000000,0.0,0.0,0.000000,0.173287,0.0]\n",
    "dataSetII = [0.0,0.0,0.000000,0.099021,0.0,0.0,0.099021,0.000000,0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm starts from this block onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"gold silver truck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#randomly initialize x\n",
    "x=np.random.rand(10,9)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A population of randomly assigned query weights\n",
    "#initializing rest of the tokens (not in the query terms) as zero\n",
    "for i in range(0,len(x)):\n",
    "    x[i][0]=0\n",
    "    x[i][1]=0\n",
    "    x[i][2]=0\n",
    "    x[i][4]=0\n",
    "    x[i][5]=0\n",
    "    x[i][6]=0\n",
    "#converting x into a list\n",
    "x=list(x)\n",
    "#list of lists\n",
    "x=[x[i:i+1] for i  in range(0, len(x), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crossover\n",
    "def crossover(docA, docB):\n",
    "    #a copy a docA and docB\n",
    "    copydocA = docA\n",
    "    copydocB = docB\n",
    "    #This takes the top 4 chromosomes and does a crossover\n",
    "    #The children are then allocated the top 4 places in the new population\n",
    "    #And the Parents involved in crossover are placed at the bottom of the population\n",
    "    #In this way we have a new population of 10\n",
    "    #top 6 being the newly created children\n",
    "    #last 4 being the parents of these children.\n",
    "    for k in range(0,4):\n",
    "        #k-th weights into temp\n",
    "        temp=docA[k][0]\n",
    "        #places the parent at the bottom\n",
    "        docA[len(docA)-1-k][0]=copydocA[k][0]\n",
    "        #Crossover occurs at the 5th position\n",
    "        docA[k][0][:5]=docA[k+1][0][:5]\n",
    "        docA[k+1][0][:5]=temp[:5]\n",
    "        #same steps for docB\n",
    "        temp=docB[k][0]\n",
    "        docB[len(docB)-1-k][0]=copydocB[k][0]\n",
    "        docB[k][0][:5]=docB[k+1][0][:5]\n",
    "        docB[k+1][0][:5]=temp[:5]\n",
    "    #returns the new populations for docA and docB\n",
    "    return (docA, docB)\n",
    "\n",
    "# mutation\n",
    "def mutation(docA, docB):\n",
    "    #Mutation occurs on the best solution in the population\n",
    "    docA[0][0][3:7] = docA[0][0][3:7]* 1.1\n",
    "    docB[0][0][3:7] = docB[0][0][3:7]* 1.1\n",
    "    return (docA,docB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same random weights put into x1 and x2 for the respective documents at the beginning\n",
    "x1=x\n",
    "x2=x\n",
    "\n",
    "#This loop will go on for 100 generations\n",
    "for j in range(0,100):\n",
    "    #y and z are lists that would contain the cosine similarities (fitness function).\n",
    "    y=[]\n",
    "    z=[]\n",
    "    for i in range(0,len(x)):\n",
    "        #calculation of cosine similarity\n",
    "        y.append(1 - spatial.distance.cosine(x1[i][0],dataSetI))\n",
    "        z.append(1 - spatial.distance.cosine(x2[i][0],dataSetII))\n",
    "    \n",
    "    #sublists\n",
    "    y=[y[i:i+1] for i  in range(0, len(y), 1)]\n",
    "    z=[z[i:i+1] for i  in range(0, len(z), 1)]\n",
    "    \n",
    "    #docA and docB contains the weights and their cosine similarity\n",
    "    docA=[]\n",
    "    docB=[]\n",
    "    for i in range(0,len(y)):\n",
    "        docA.append(x1[i]+y[i])\n",
    "        docB.append(x2[i]+z[i])\n",
    "    #Sorting\n",
    "    docA.sort(key=lambda tup: tup[1],reverse=True)\n",
    "    docB.sort(key=lambda tup: tup[1],reverse=True)\n",
    "    \n",
    "    if(j!=51):#crossover function called at this point\n",
    "        co=crossover(docA,docB)\n",
    "        docA=co[0]\n",
    "        docB=co[1]\n",
    "\n",
    "    if(j==51):#mutation occurs in the 51st generation.\n",
    "        mu=mutation(docA,docB)\n",
    "        docA=mu[0]\n",
    "        docB=mu[1]\n",
    "    \n",
    "    #assigns docA in x1 and x2 for next generation \n",
    "    x1=docA\n",
    "    x2=docB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query weights with cosine similarity for the 1st document\n",
      "[0.         0.         0.         0.04953417 0.         0.\n",
      " 0.         0.09047376 0.02497273] 0.7625098706293373\n",
      "Query weights with cosine similarity for the 2nd document\n",
      "[0.         0.         0.         0.04878782 0.         0.\n",
      " 0.         0.0417731  0.00965656] 0.5311507273844291\n",
      "+++\n",
      "' delivery of silver arrived in a silver truck '  is more relevant with respect to the query.\n",
      "+++\n"
     ]
    }
   ],
   "source": [
    "print(\"Query weights with cosine similarity for the 1st document\")\n",
    "print(x1[0][0],1 - spatial.distance.cosine(x1[0][0],dataSetI))\n",
    "print(\"Query weights with cosine similarity for the 2nd document\")\n",
    "print(x2[0][0],1 - spatial.distance.cosine(x2[0][0],dataSetII))\n",
    "\n",
    "\n",
    "csA=1 - spatial.distance.cosine(x1[0][0],dataSetI)\n",
    "csB=1 - spatial.distance.cosine(x2[0][0],dataSetII)\n",
    "            \n",
    "\n",
    "if(csA>csB):\n",
    "    print(\"+++\")\n",
    "    print(\"'\",documentA,\"'\",\" is more relevant with respect to the query.\")\n",
    "    print(\"+++\")\n",
    "else:\n",
    "    print(\"+++\")\n",
    "    print(\"'\",documentB,\"'\",\" is more relevant with respect to the query.\")\n",
    "    print(\"+++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of GA's query weights find to normal similarity computation using the tf-idf matrices of the query with the 2 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using normal tf-idf to compute similarity of the query with both the docs\n",
    "# Compute tf idf of the document and query\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# defining the 2 documents considered\n",
    "documentA = [\"delivery of silver arrived in a silver truck\"]\n",
    "documentB = [\"shipment of gold arrived in a truck\"]\n",
    "\n",
    "# Computing tf-idf of the documents and query\n",
    "tf = TfidfVectorizer(analyzer='word')\n",
    "tfidf_doc1 =  tf.fit_transform(documentA)\n",
    "qu_tfidf1 = tf.transform([query])\n",
    "tfidf_doc2 =  tf.fit_transform(documentB)\n",
    "qu_tfidf2 = tf.transform([query])\n",
    "\n",
    "# base values for the similarities obtained\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_sim_doc1 = 1 - spatial.distance.cosine(qu_tfidf1.toarray(), tfidf_doc1.toarray())\n",
    "cosine_sim_doc2 = 1 - spatial.distance.cosine(qu_tfidf2.toarray(), tfidf_doc2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067811865476"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_doc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the GA's performance in finding out weights for the query terms; we see a higher similarity is returned for the first document compared to second which is good since the first document is more relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations:\n",
    "1. We are using bag of words model here to find out simialrity which totally disregards words co-occurence. \n",
    "2. Secondly, we have used 100 iterations anfd have not waited until the algorithm converges by itself. We had tried letting the algorithm execute until the cosine similarity value exceeds that of normal tf-idf cosine simailrity but that'a a naive way to evaluate fitness I think; since we may just keep getting better weights later too.\n",
    "3. Ideally, we should have used random point crossover instead of fixing the position since it might result in inclusion of new terms in our query which is better for document search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
